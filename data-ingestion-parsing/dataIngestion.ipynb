{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff11f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88b713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b499c7b",
   "metadata": {},
   "source": [
    "## Understanding Documents in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee4f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document created successfully.\n",
      "Document Source: This is the content of the document.\n",
      "Document metadata: {'source': 'exmaple.txt', 'pages': 1, 'author': 'Prithviraj Acharya', 'date_created': '2025-01-01', 'custom_key': 'custom_value'}\n"
     ]
    }
   ],
   "source": [
    "##Understanding Documents in LangChain\n",
    "doc = Document(\n",
    "    page_content=\"This is the content of the document.\",\n",
    "    metadata={\"source\":\"exmaple.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\":\"Prithviraj Acharya\",\n",
    "        \"date_created\":\"2025-01-01\",\n",
    "        \"custom_key\":\"custom_value\"\n",
    "        },\n",
    ")\n",
    "\n",
    "print(\"Document created successfully.\")\n",
    "print(f\"Document Source: {doc.page_content}\")\n",
    "print(f\"Document metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6161fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple txt file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9413ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"âœ… Sample text files created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c402b69",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719b3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s).\n",
      "type of document: <class 'langchain_core.documents.base.Document'>\n",
      "Document content preview:\n",
      "Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
      "Created by Guido van Rossum and first released in 1991, Python has b...\n",
      "Document metadata:\n",
      "{'source': '../data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "# Text loader - Read single file\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\")\n",
    "documents = loader.load()       \n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n",
    "print(f\"type of document: {type(documents[0])}\")\n",
    "print(f\"Document content preview:\\n{documents[0].page_content[:200]}...\")\n",
    "print(f\"Document metadata:\\n{documents[0].metadata}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de90a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 2126.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Content Preview: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n",
      "Source: ..\\data\\text_files\\machine_learning.txt\n",
      "Type: <class 'langchain_core.documents.base.Document'>\n",
      "Length of document: 575 characters\n",
      "\n",
      "Document 2:\n",
      "Content Preview: Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for ...\n",
      "Source: ..\\data\\text_files\\python_intro.txt\n",
      "Type: <class 'langchain_core.documents.base.Document'>\n",
      "Length of document: 489 characters\n",
      "\n",
      "Total documents loaded: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "\n",
    "for i,doc in enumerate(documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"Content Preview: {doc.page_content[:100]}...\")\n",
    "    print(f\"Source: {doc.metadata['source']}\")\n",
    "    print(f\"Type: {type(doc)}\")\n",
    "    print(f'Length of document: {len(doc.page_content)} characters')\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce7079",
   "metadata": {},
   "source": [
    "## Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df76476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. CharacterTextSplitter\n",
      "Total chunks created: 4\n",
      "first chunk preview::\n",
      "Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve...\n"
     ]
    }
   ],
   "source": [
    "# Method 1 - character-based splitting\n",
    "\n",
    "text = documents[0].page_content\n",
    "\n",
    "print('1. CharacterTextSplitter')\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # split on new line character\n",
    "    chunk_size=200, # max chunk size in characters\n",
    "    chunk_overlap=20, # max overlap between chunks in characters\n",
    "    length_function=len # How to measure chunk size\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "\n",
    "print(f\"Total chunks created: {len(char_chunks)}\")\n",
    "print(f\"first chunk preview::\\n{char_chunks[0][:200]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915c5cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. RecursiveCharacterTextSplitter\n",
      "Total chunks created: 6\n",
      "first chunk preview::\n",
      "Machine Learning Basics...\n"
     ]
    }
   ],
   "source": [
    "# Method 2 - Recursive Character-based splitting (Most Recommended)\n",
    "\n",
    "text = documents[0].page_content\n",
    "\n",
    "print('2. RecursiveCharacterTextSplitter')\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], # split on multiple separators in order\n",
    "    chunk_size=200, # max chunk size in characters\n",
    "    chunk_overlap=20, # max overlap between chunks in characters\n",
    "    length_function=len # How to measure chunk size\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "\n",
    "print(f\"Total chunks created: {len(recursive_chunks)}\")\n",
    "print(f\"first chunk preview::\\n{recursive_chunks[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d81db987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "--------------------\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "--------------------\n",
      "that can access data and use it to learn for themselves.\n",
      "--------------------\n",
      "Types of Machine Learning:\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "--------------------\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(recursive_chunks[0])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[2])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[3])\n",
    "print(\"--------------------\")\n",
    "print(recursive_chunks[4])\n",
    "print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1536421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. TokenTextSplitter\n",
      "Total chunks created: 6\n",
      "first chunk preview::\n",
      "Machine Learning Basics...\n",
      "Total chunks created: 6\n",
      "first chunk preview::\n",
      "Machine Learning Basics...\n"
     ]
    }
   ],
   "source": [
    "#  Method 3 - Token-based splitting\n",
    "\n",
    "text = documents[0].page_content\n",
    "print('3. TokenTextSplitter')\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50, # max chunk size in tokens\n",
    "    chunk_overlap=10, # max overlap between chunks in tokens\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "\n",
    "print(f\"Total chunks created: {len(recursive_chunks)}\")\n",
    "print(f\"first chunk preview::\\n{recursive_chunks[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26f45b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Text Splitter Comparison:\n",
      "\n",
      "ðŸ”„ RecursiveCharacterTextSplitter:\n",
      "âœ… Pros: Smart splitting, preserves structure, best for RAG\n",
      "âŒ Cons: Slower, character-based not token-aware\n",
      "\n",
      "ðŸ“ CharacterTextSplitter:\n",
      "âœ… Pros: Fast, predictable sizes, simple\n",
      "âŒ Cons: Breaks text awkwardly, ignores boundaries\n",
      "\n",
      "ðŸŽ« TokenTextSplitter:\n",
      "âœ… Pros: Token-aware, respects word boundaries, LLM-optimized\n",
      "âŒ Cons: Slower, tokenizer-dependent, less intuitive\n",
      "\n",
      "ðŸ’¡ Recommendation: Use RecursiveCharacterTextSplitter for most cases\n",
      "\n",
      "ðŸ“ˆ Results:\n",
      "Character: 4 chunks, 562 chars\n",
      "Recursive: 6 chunks, 560 chars\n",
      "Token: 3 chunks, 666 chars\n",
      "\n",
      "ðŸ‘€ Previews:\n",
      "Character: Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems...\n",
      "Recursive: Machine Learning Basics\n",
      "Token: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n"
     ]
    }
   ],
   "source": [
    "# Comparison of different splitting methods\n",
    "\n",
    "print('ðŸ“Š Text Splitter Comparison:')\n",
    "\n",
    "print('\\nðŸ”„ RecursiveCharacterTextSplitter:')\n",
    "print('âœ… Pros: Smart splitting, preserves structure, best for RAG')\n",
    "print('âŒ Cons: Slower, character-based not token-aware')\n",
    "\n",
    "print('\\nðŸ“ CharacterTextSplitter:')\n",
    "print('âœ… Pros: Fast, predictable sizes, simple')\n",
    "print('âŒ Cons: Breaks text awkwardly, ignores boundaries')\n",
    "\n",
    "print('\\nðŸŽ« TokenTextSplitter:')\n",
    "print('âœ… Pros: Token-aware, respects word boundaries, LLM-optimized')\n",
    "print('âŒ Cons: Slower, tokenizer-dependent, less intuitive')\n",
    "\n",
    "print('\\nðŸ’¡ Recommendation: Use RecursiveCharacterTextSplitter for most cases')\n",
    "\n",
    "# Results\n",
    "print(f\"\\nðŸ“ˆ Results:\")\n",
    "print(f\"Character: {len(char_chunks)} chunks, {sum(len(c) for c in char_chunks)} chars\")\n",
    "print(f\"Recursive: {len(recursive_chunks)} chunks, {sum(len(c) for c in recursive_chunks)} chars\")\n",
    "print(f\"Token: {len(token_chunks)} chunks, {sum(len(c) for c in token_chunks)} chars\")\n",
    "\n",
    "# Safe preview function\n",
    "def safe_preview(text, length=100):\n",
    "    try:\n",
    "        return text[:length] + \"...\" if len(text) > length else text\n",
    "    except UnicodeEncodeError:\n",
    "        # Remove problematic characters\n",
    "        return ''.join(c for c in text[:length] if ord(c) < 0x10000) + \"...\"\n",
    "\n",
    "print(f\"\\nðŸ‘€ Previews:\")\n",
    "print(f\"Character: {safe_preview(char_chunks[0])}\")\n",
    "print(f\"Recursive: {safe_preview(recursive_chunks[0])}\")\n",
    "print(f\"Token: {safe_preview(token_chunks[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17022646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b548780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a231ecb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379063c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
